{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Summation and Catastrophic Cancellation\n",
                "\n",
                "## Objective\n",
                "\n",
                "Study how rounding errors accumulate in summation and demonstrate catastrophic cancellation:\n",
                "- Naive summation error growth\n",
                "- Kahan (compensated) summation\n",
                "- Pairwise summation\n",
                "- Catastrophic cancellation examples\n",
                "\n",
                "## Error Growth in Naive Summation\n",
                "\n",
                "For naive left-to-right summation of $n$ numbers, the rounding error grows as:\n",
                "\n",
                "$$|\\text{error}| \\leq nu|\\sum x_i|$$\n",
                "\n",
                "where $u$ is the unit roundoff. This is a **linear growth** in $n$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import sys\n",
                "sys.path.append('..')\n",
                "\n",
                "from utils.floating_point_tools import naive_sum, kahan_sum, pairwise_sum\n",
                "from utils.error_metrics import relative_error\n",
                "\n",
                "np.random.seed(42)\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "plt.rcParams['font.size'] = 11"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiment 1: Error Growth vs Problem Size"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test summation error growth\n",
                "sizes = np.logspace(2, 7, 20).astype(int)\n",
                "naive_errors = []\n",
                "kahan_errors = []\n",
                "pairwise_errors = []\n",
                "numpy_errors = []\n",
                "\n",
                "for n in sizes:\n",
                "    # Generate random numbers\n",
                "    arr = np.random.randn(n)\n",
                "    \n",
                "    # Compute \"exact\" sum using higher precision\n",
                "    exact = np.sum(arr.astype(np.float128))\n",
                "    \n",
                "    # Compute sums with different methods\n",
                "    s_naive = naive_sum(arr)\n",
                "    s_kahan = kahan_sum(arr)\n",
                "    s_pairwise = pairwise_sum(arr)\n",
                "    s_numpy = np.sum(arr)\n",
                "    \n",
                "    # Record relative errors\n",
                "    naive_errors.append(abs(s_naive - exact) / abs(exact))\n",
                "    kahan_errors.append(abs(s_kahan - exact) / abs(exact))\n",
                "    pairwise_errors.append(abs(s_pairwise - exact) / abs(exact))\n",
                "    numpy_errors.append(abs(s_numpy - exact) / abs(exact))\n",
                "\n",
                "# Plot results\n",
                "plt.figure(figsize=(14, 6))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.loglog(sizes, naive_errors, 'o-', label='Naive', linewidth=2)\n",
                "plt.loglog(sizes, kahan_errors, 's-', label='Kahan', linewidth=2)\n",
                "plt.loglog(sizes, pairwise_errors, '^-', label='Pairwise', linewidth=2)\n",
                "plt.loglog(sizes, numpy_errors, 'd-', label='NumPy', linewidth=2)\n",
                "\n",
                "# Theoretical bounds\n",
                "eps = np.finfo(np.float64).eps\n",
                "plt.loglog(sizes, sizes * eps, 'k--', alpha=0.5, label=r'$n \\varepsilon$')\n",
                "plt.loglog(sizes, np.log2(sizes) * eps, 'k:', alpha=0.5, label=r'$\\log_2(n) \\varepsilon$')\n",
                "\n",
                "plt.xlabel('Number of summands (n)')\n",
                "plt.ylabel('Relative error')\n",
                "plt.title('Summation Error Growth')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "# Improvement factor\n",
                "improvement_kahan = np.array(naive_errors) / np.array(kahan_errors)\n",
                "improvement_pairwise = np.array(naive_errors) / np.array(pairwise_errors)\n",
                "\n",
                "plt.semilogx(sizes, improvement_kahan, 's-', label='Kahan vs Naive', linewidth=2)\n",
                "plt.semilogx(sizes, improvement_pairwise, '^-', label='Pairwise vs Naive', linewidth=2)\n",
                "plt.xlabel('Number of summands (n)')\n",
                "plt.ylabel('Error reduction factor')\n",
                "plt.title('Improvement Over Naive Summation')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../plots/02_summation_error_growth.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"For n = {sizes[-1]:,}:\")\n",
                "print(f\"Naive error:     {naive_errors[-1]:.6e}\")\n",
                "print(f\"Kahan error:     {kahan_errors[-1]:.6e}\")\n",
                "print(f\"Pairwise error:  {pairwise_errors[-1]:.6e}\")\n",
                "print(f\"Improvement:     {improvement_kahan[-1]:.1f}x (Kahan)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Kahan Summation Algorithm\n",
                "\n",
                "Kahan's compensated summation maintains a running compensation for lost low-order bits:\n",
                "\n",
                "```\n",
                "sum = 0\n",
                "c = 0  # compensation\n",
                "for x in array:\n",
                "    y = x - c\n",
                "    t = sum + y\n",
                "    c = (t - sum) - y\n",
                "    sum = t\n",
                "```\n",
                "\n",
                "**Error bound**: $O(\\varepsilon) + O(n\\varepsilon^2)$ instead of $O(n\\varepsilon)$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiment 2: Catastrophic Cancellation\n",
                "\n",
                "Subtracting nearly equal numbers loses significant digits."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.floating_point_tools import catastrophic_cancellation_example\n",
                "\n",
                "# Example: (1 - cos(x)) / x^2 for small x\n",
                "x_values = np.logspace(-10, -1, 100)\n",
                "\n",
                "unstable_result = catastrophic_cancellation_example(x_values, method='unstable')\n",
                "stable_result = catastrophic_cancellation_example(x_values, method='stable')\n",
                "\n",
                "# Exact value (limit as x -> 0 is 1/2)\n",
                "exact = 0.5 * np.ones_like(x_values)\n",
                "\n",
                "plt.figure(figsize=(14, 6))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.semilogx(x_values, unstable_result, 'o-', label='Unstable: (1 - cos(x))/x²', markersize=4)\n",
                "plt.semilogx(x_values, stable_result, 's-', label='Stable: reformulated', markersize=4)\n",
                "plt.axhline(0.5, color='k', linestyle='--', label='Exact (0.5)')\n",
                "plt.xlabel('x')\n",
                "plt.ylabel('Function value')\n",
                "plt.title('Catastrophic Cancellation Example')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "unstable_error = np.abs(unstable_result - exact) / exact\n",
                "stable_error = np.abs(stable_result - exact) / exact\n",
                "\n",
                "plt.loglog(x_values, unstable_error, 'o-', label='Unstable', markersize=4)\n",
                "plt.loglog(x_values, stable_error, 's-', label='Stable', markersize=4)\n",
                "plt.xlabel('x')\n",
                "plt.ylabel('Relative error')\n",
                "plt.title('Error Comparison')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../plots/02_catastrophic_cancellation.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiment 3: Quadratic Formula Stability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.floating_point_tools import quadratic_formula\n",
                "\n",
                "# Solve x^2 - 2bx + 1 = 0 for large b\n",
                "# Exact roots: b ± sqrt(b^2 - 1) ≈ b ± b for large b\n",
                "b_values = np.logspace(1, 8, 50)\n",
                "\n",
                "unstable_errors = []\n",
                "stable_errors = []\n",
                "\n",
                "for b in b_values:\n",
                "    a, c = 1.0, 1.0\n",
                "    \n",
                "    # Exact roots (using high precision)\n",
                "    b_hp = np.float128(b)\n",
                "    disc = b_hp**2 - 4\n",
                "    r1_exact = (b_hp + np.sqrt(disc)) / 2\n",
                "    r2_exact = (b_hp - np.sqrt(disc)) / 2\n",
                "    \n",
                "    # Unstable formula\n",
                "    r1_unstable, r2_unstable = quadratic_formula(a, -2*b, c, method='unstable')\n",
                "    \n",
                "    # Stable formula\n",
                "    r1_stable, r2_stable = quadratic_formula(a, -2*b, c, method='stable')\n",
                "    \n",
                "    # Compute errors for the smaller root (more sensitive)\n",
                "    unstable_err = abs(r2_unstable - r2_exact) / abs(r2_exact)\n",
                "    stable_err = abs(r2_stable - r2_exact) / abs(r2_exact)\n",
                "    \n",
                "    unstable_errors.append(unstable_err)\n",
                "    stable_errors.append(stable_err)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.loglog(b_values, unstable_errors, 'o-', label='Unstable formula', linewidth=2)\n",
                "plt.loglog(b_values, stable_errors, 's-', label='Stable formula', linewidth=2)\n",
                "plt.axhline(np.finfo(np.float64).eps, color='k', linestyle='--', \n",
                "            label=r'Machine epsilon', alpha=0.5)\n",
                "plt.xlabel('Parameter b')\n",
                "plt.ylabel('Relative error (smaller root)')\n",
                "plt.title('Quadratic Formula Stability')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.savefig('../plots/02_quadratic_formula.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiment 4: log1p and expm1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.floating_point_tools import log1p_example, expm1_example\n",
                "\n",
                "x_small = np.logspace(-16, -1, 100)\n",
                "\n",
                "# log(1 + x)\n",
                "log1p_unstable = log1p_example(x_small, method='unstable')\n",
                "log1p_stable = log1p_example(x_small, method='stable')\n",
                "log1p_exact = np.log1p(x_small.astype(np.float128)).astype(np.float64)\n",
                "\n",
                "# exp(x) - 1\n",
                "expm1_unstable = expm1_example(x_small, method='unstable')\n",
                "expm1_stable = expm1_example(x_small, method='stable')\n",
                "expm1_exact = np.expm1(x_small.astype(np.float128)).astype(np.float64)\n",
                "\n",
                "plt.figure(figsize=(14, 6))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "log1p_unstable_err = np.abs(log1p_unstable - log1p_exact) / np.abs(log1p_exact)\n",
                "log1p_stable_err = np.abs(log1p_stable - log1p_exact) / np.abs(log1p_exact)\n",
                "plt.loglog(x_small, log1p_unstable_err, 'o-', label='log(1+x) unstable', markersize=4)\n",
                "plt.loglog(x_small, log1p_stable_err, 's-', label='log1p stable', markersize=4)\n",
                "plt.xlabel('x')\n",
                "plt.ylabel('Relative error')\n",
                "plt.title('log(1 + x) for small x')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "expm1_unstable_err = np.abs(expm1_unstable - expm1_exact) / np.abs(expm1_exact)\n",
                "expm1_stable_err = np.abs(expm1_stable - expm1_exact) / np.abs(expm1_exact)\n",
                "plt.loglog(x_small, expm1_unstable_err, 'o-', label='exp(x)-1 unstable', markersize=4)\n",
                "plt.loglog(x_small, expm1_stable_err, 's-', label='expm1 stable', markersize=4)\n",
                "plt.xlabel('x')\n",
                "plt.ylabel('Relative error')\n",
                "plt.title('exp(x) - 1 for small x')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../plots/02_log1p_expm1.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Key Takeaways\n",
                "\n",
                "1. **Naive summation**: Error grows linearly with $n$, reaching $O(n\\varepsilon)$\n",
                "\n",
                "2. **Kahan summation**: Reduces error to $O(\\varepsilon)$, dramatic improvement for large $n$\n",
                "\n",
                "3. **Pairwise summation**: Error grows as $O(\\log n \\cdot \\varepsilon)$, good balance\n",
                "\n",
                "4. **Catastrophic cancellation**: Subtracting nearly equal numbers loses precision\n",
                "\n",
                "5. **Algorithmic reformulation**: Often the best solution (e.g., log1p, expm1)\n",
                "\n",
                "6. **Practical impact**: For $n = 10^7$, Kahan can improve accuracy by $10^7$ times!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}